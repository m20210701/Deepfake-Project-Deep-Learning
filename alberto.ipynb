{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets.mnist import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from numpy import expand_dims\n",
    "from numpy import ones\n",
    "from numpy import zeros\n",
    "from numpy.random import randn\n",
    "from numpy.random import rand\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Faces for Training: 6430\n"
     ]
    }
   ],
   "source": [
    "# Generation resolution factor \n",
    "GENERATE_RES = 3 # (1=32, 2=64, 3=96, 4=128, etc.)\n",
    "\n",
    "# rows/cols (should be square)\n",
    "GENERATE_SQUARE = 32 * GENERATE_RES \n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "# Preview image \n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 16\n",
    "\n",
    "# Size vector to generate images from\n",
    "SEED_SIZE = 100\n",
    "\n",
    "# Configuration\n",
    "DATA_FOLDER = r\"C:\\Users\\Alberto Parenti\\Downloads\\STUDY\\NOVA IMS\\DEEP LEARNING\\PROJECT\\crop_part1 (extract.me)\\crop_part1\"\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 60000\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "print(f\"Real Faces for Training: {len(os.listdir(os.path.join(DATA_FOLDER)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need a way to convert our training set into the correct format\n",
    "def load_real_samples(image_path):\n",
    "\n",
    "    #Defining master array\n",
    "    master_list = list()\n",
    "\n",
    "    for image in os.listdir(image_path):\n",
    "        #loading image\n",
    "        img = load_img(os.path.join(image_path,image), grayscale=True)\n",
    "\n",
    "        # convert to numpy array\n",
    "        img_array = img_to_array(img)\n",
    "        #Standardizing to float\n",
    "        img_array = img_array.astype(\"float32\")\n",
    "        #Grtting value between 0 and 1\n",
    "        img_array/=255.0\n",
    "\n",
    "        master_list.append(img_array)\n",
    "\n",
    "    return np.array(master_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the descriminator model\n",
    "def define_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, \n",
    "                     padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 100, 100, 32)      320       \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 100, 100, 32)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 100, 100, 32)      0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 50, 50, 64)        18496     \n",
      "                                                                 \n",
      " zero_padding2d_1 (ZeroPaddi  (None, 51, 51, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 51, 51, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 51, 51, 64)        0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 51, 51, 64)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 26, 26, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 26, 26, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 26, 26, 128)       0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 26, 26, 128)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 26, 26, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 26, 26, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 26, 26, 256)       0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 26, 26, 256)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 26, 26, 512)       1180160   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 26, 26, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 26, 26, 512)       0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 26, 26, 512)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 346112)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 346113    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,917,953\n",
      "Trainable params: 1,916,033\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "#calling the function to define the model\n",
    "model = define_discriminator(image_shape=(200,200,1))\n",
    "\n",
    "#summarizing the model\n",
    "model.summary()\n",
    "\n",
    "#plotting the model\n",
    "plot_model(model, to_file = \"discriminator_plot.png\", show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we are training the model we need to provide it with both real and generated characters\n",
    "# So we need to define a function to provide it with a random subset of real images\n",
    "\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate n fake samples with class labels as for the time being we don't have a generator model\n",
    "def generate_fake_samples(n_samples):\n",
    "\t# generate uniform random numbers in [0,1]\n",
    "\tX = rand(200 * 200 * n_samples)\n",
    "\t# reshape into a batch of grayscale images\n",
    "\tX = X.reshape((n_samples, 200, 200, 1))\n",
    "\t# generate 'fake' class labels (0)\n",
    "\ty = zeros((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alberto Parenti\\anaconda3\\envs\\datamining_practical\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.87058824],\n",
       "         [0.92156863],\n",
       "         [0.9254902 ],\n",
       "         ...,\n",
       "         [0.9098039 ],\n",
       "         [0.88235295],\n",
       "         [0.8862745 ]],\n",
       "\n",
       "        [[0.90588236],\n",
       "         [0.9372549 ],\n",
       "         [0.91764706],\n",
       "         ...,\n",
       "         [0.9019608 ],\n",
       "         [0.8862745 ],\n",
       "         [0.8862745 ]],\n",
       "\n",
       "        [[0.9254902 ],\n",
       "         [0.9372549 ],\n",
       "         [0.9019608 ],\n",
       "         ...,\n",
       "         [0.8862745 ],\n",
       "         [0.8901961 ],\n",
       "         [0.88235295]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1764706 ],\n",
       "         [0.22352941],\n",
       "         [0.24705882],\n",
       "         ...,\n",
       "         [0.68235296],\n",
       "         [0.7176471 ],\n",
       "         [0.73333335]],\n",
       "\n",
       "        [[0.1882353 ],\n",
       "         [0.18039216],\n",
       "         [0.1764706 ],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.17254902],\n",
       "         [0.12941177],\n",
       "         [0.11764706],\n",
       "         ...,\n",
       "         [0.99215686],\n",
       "         [1.        ],\n",
       "         [1.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.16862746],\n",
       "         [0.16470589],\n",
       "         [0.15686275],\n",
       "         ...,\n",
       "         [0.30980393],\n",
       "         [0.29411766],\n",
       "         [0.28627452]],\n",
       "\n",
       "        [[0.16862746],\n",
       "         [0.16470589],\n",
       "         [0.15686275],\n",
       "         ...,\n",
       "         [0.3137255 ],\n",
       "         [0.29803923],\n",
       "         [0.2901961 ]],\n",
       "\n",
       "        [[0.16470589],\n",
       "         [0.15686275],\n",
       "         [0.15294118],\n",
       "         ...,\n",
       "         [0.31764707],\n",
       "         [0.30980393],\n",
       "         [0.3019608 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2901961 ],\n",
       "         [0.30588236],\n",
       "         [0.32156864],\n",
       "         ...,\n",
       "         [0.29411766],\n",
       "         [0.2784314 ],\n",
       "         [0.27058825]],\n",
       "\n",
       "        [[0.29411766],\n",
       "         [0.30588236],\n",
       "         [0.3254902 ],\n",
       "         ...,\n",
       "         [0.3019608 ],\n",
       "         [0.2901961 ],\n",
       "         [0.2784314 ]],\n",
       "\n",
       "        [[0.2901961 ],\n",
       "         [0.29803923],\n",
       "         [0.30980393],\n",
       "         ...,\n",
       "         [0.30980393],\n",
       "         [0.29411766],\n",
       "         [0.28627452]]],\n",
       "\n",
       "\n",
       "       [[[0.3372549 ],\n",
       "         [0.3137255 ],\n",
       "         [0.3019608 ],\n",
       "         ...,\n",
       "         [0.46666667],\n",
       "         [0.4745098 ],\n",
       "         [0.48235294]],\n",
       "\n",
       "        [[0.34509805],\n",
       "         [0.31764707],\n",
       "         [0.30588236],\n",
       "         ...,\n",
       "         [0.45490196],\n",
       "         [0.4745098 ],\n",
       "         [0.5019608 ]],\n",
       "\n",
       "        [[0.3529412 ],\n",
       "         [0.3254902 ],\n",
       "         [0.30980393],\n",
       "         ...,\n",
       "         [0.44705883],\n",
       "         [0.46666667],\n",
       "         [0.52156866]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.01568628],\n",
       "         [0.01568628],\n",
       "         [0.01960784],\n",
       "         ...,\n",
       "         [0.18431373],\n",
       "         [0.19607843],\n",
       "         [0.21960784]],\n",
       "\n",
       "        [[0.01568628],\n",
       "         [0.01568628],\n",
       "         [0.01960784],\n",
       "         ...,\n",
       "         [0.18431373],\n",
       "         [0.19607843],\n",
       "         [0.21176471]],\n",
       "\n",
       "        [[0.01568628],\n",
       "         [0.01568628],\n",
       "         [0.01960784],\n",
       "         ...,\n",
       "         [0.19607843],\n",
       "         [0.2       ],\n",
       "         [0.19607843]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.03529412],\n",
       "         [0.01568628],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.5294118 ],\n",
       "         [0.53333336],\n",
       "         [0.53333336]],\n",
       "\n",
       "        [[0.03137255],\n",
       "         [0.01176471],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.5254902 ],\n",
       "         [0.5254902 ],\n",
       "         [0.5254902 ]],\n",
       "\n",
       "        [[0.02745098],\n",
       "         [0.01176471],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.5137255 ],\n",
       "         [0.5137255 ],\n",
       "         [0.5137255 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314],\n",
       "         [0.01176471],\n",
       "         [0.01176471],\n",
       "         ...,\n",
       "         [0.01568628],\n",
       "         [0.04313726],\n",
       "         [0.08235294]],\n",
       "\n",
       "        [[0.00784314],\n",
       "         [0.01176471],\n",
       "         [0.01176471],\n",
       "         ...,\n",
       "         [0.01568628],\n",
       "         [0.04313726],\n",
       "         [0.07843138]],\n",
       "\n",
       "        [[0.00784314],\n",
       "         [0.01176471],\n",
       "         [0.01176471],\n",
       "         ...,\n",
       "         [0.01568628],\n",
       "         [0.03921569],\n",
       "         [0.07450981]]],\n",
       "\n",
       "\n",
       "       [[[0.83137256],\n",
       "         [0.8392157 ],\n",
       "         [0.8156863 ],\n",
       "         ...,\n",
       "         [0.8745098 ],\n",
       "         [0.8745098 ],\n",
       "         [0.8784314 ]],\n",
       "\n",
       "        [[0.81960785],\n",
       "         [0.827451  ],\n",
       "         [0.81960785],\n",
       "         ...,\n",
       "         [0.87058824],\n",
       "         [0.87058824],\n",
       "         [0.87058824]],\n",
       "\n",
       "        [[0.8235294 ],\n",
       "         [0.8235294 ],\n",
       "         [0.8235294 ],\n",
       "         ...,\n",
       "         [0.8627451 ],\n",
       "         [0.8666667 ],\n",
       "         [0.8666667 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9411765 ],\n",
       "         [0.92941177],\n",
       "         [0.81960785],\n",
       "         ...,\n",
       "         [0.05490196],\n",
       "         [0.00392157],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.9411765 ],\n",
       "         [0.93333334],\n",
       "         [0.8509804 ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.03137255],\n",
       "         [0.01960784]],\n",
       "\n",
       "        [[0.9098039 ],\n",
       "         [0.93333334],\n",
       "         [0.88235295],\n",
       "         ...,\n",
       "         [0.01176471],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.76862746],\n",
       "         [0.75686276],\n",
       "         [0.7254902 ],\n",
       "         ...,\n",
       "         [0.98039216],\n",
       "         [0.9764706 ],\n",
       "         [0.972549  ]],\n",
       "\n",
       "        [[0.7764706 ],\n",
       "         [0.7647059 ],\n",
       "         [0.7372549 ],\n",
       "         ...,\n",
       "         [0.98039216],\n",
       "         [0.9764706 ],\n",
       "         [0.972549  ]],\n",
       "\n",
       "        [[0.7764706 ],\n",
       "         [0.77254903],\n",
       "         [0.7490196 ],\n",
       "         ...,\n",
       "         [0.98039216],\n",
       "         [0.9764706 ],\n",
       "         [0.972549  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.04705882],\n",
       "         [0.05098039],\n",
       "         [0.09803922],\n",
       "         ...,\n",
       "         [0.09019608],\n",
       "         [0.07843138],\n",
       "         [0.07058824]],\n",
       "\n",
       "        [[0.06666667],\n",
       "         [0.06666667],\n",
       "         [0.10588235],\n",
       "         ...,\n",
       "         [0.10980392],\n",
       "         [0.10980392],\n",
       "         [0.10588235]],\n",
       "\n",
       "        [[0.08627451],\n",
       "         [0.07843138],\n",
       "         [0.10196079],\n",
       "         ...,\n",
       "         [0.10196079],\n",
       "         [0.10980392],\n",
       "         [0.10980392]]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = load_real_samples(r\"C:\\Users\\Alberto Parenti\\Downloads\\STUDY\\NOVA IMS\\DEEP LEARNING\\PROJECT\\crop_part1 (extract.me)\\crop_part1\")\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.7764706 ],\n",
       "          [0.7529412 ],\n",
       "          [0.7176471 ],\n",
       "          ...,\n",
       "          [0.29411766],\n",
       "          [0.28235295],\n",
       "          [0.2627451 ]],\n",
       " \n",
       "         [[0.7607843 ],\n",
       "          [0.7372549 ],\n",
       "          [0.7019608 ],\n",
       "          ...,\n",
       "          [0.2901961 ],\n",
       "          [0.28235295],\n",
       "          [0.26666668]],\n",
       " \n",
       "         [[0.73333335],\n",
       "          [0.7137255 ],\n",
       "          [0.68235296],\n",
       "          ...,\n",
       "          [0.27450982],\n",
       "          [0.27058825],\n",
       "          [0.2627451 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.02352941],\n",
       "          [0.02352941],\n",
       "          [0.01960784],\n",
       "          ...,\n",
       "          [0.22352941],\n",
       "          [0.22352941],\n",
       "          [0.22352941]],\n",
       " \n",
       "         [[0.02352941],\n",
       "          [0.02352941],\n",
       "          [0.01960784],\n",
       "          ...,\n",
       "          [0.19215687],\n",
       "          [0.19215687],\n",
       "          [0.19215687]],\n",
       " \n",
       "         [[0.02745098],\n",
       "          [0.02352941],\n",
       "          [0.01568628],\n",
       "          ...,\n",
       "          [0.16862746],\n",
       "          [0.17254902],\n",
       "          [0.17254902]]],\n",
       " \n",
       " \n",
       "        [[[0.01568628],\n",
       "          [0.01176471],\n",
       "          [0.01176471],\n",
       "          ...,\n",
       "          [0.31764707],\n",
       "          [0.33333334],\n",
       "          [0.34509805]],\n",
       " \n",
       "         [[0.01960784],\n",
       "          [0.01568628],\n",
       "          [0.01176471],\n",
       "          ...,\n",
       "          [0.32156864],\n",
       "          [0.33333334],\n",
       "          [0.34509805]],\n",
       " \n",
       "         [[0.02352941],\n",
       "          [0.02352941],\n",
       "          [0.01960784],\n",
       "          ...,\n",
       "          [0.32156864],\n",
       "          [0.3372549 ],\n",
       "          [0.34901962]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.02745098],\n",
       "          [0.02745098],\n",
       "          [0.02745098],\n",
       "          ...,\n",
       "          [0.0627451 ],\n",
       "          [0.07058824],\n",
       "          [0.07450981]],\n",
       " \n",
       "         [[0.02745098],\n",
       "          [0.02745098],\n",
       "          [0.02745098],\n",
       "          ...,\n",
       "          [0.06666667],\n",
       "          [0.07450981],\n",
       "          [0.08235294]],\n",
       " \n",
       "         [[0.02745098],\n",
       "          [0.02745098],\n",
       "          [0.02745098],\n",
       "          ...,\n",
       "          [0.07058824],\n",
       "          [0.07843138],\n",
       "          [0.08235294]]],\n",
       " \n",
       " \n",
       "        [[[0.4627451 ],\n",
       "          [0.45882353],\n",
       "          [0.45882353],\n",
       "          ...,\n",
       "          [0.15294118],\n",
       "          [0.14509805],\n",
       "          [0.16470589]],\n",
       " \n",
       "         [[0.45882353],\n",
       "          [0.45882353],\n",
       "          [0.45490196],\n",
       "          ...,\n",
       "          [0.15294118],\n",
       "          [0.15294118],\n",
       "          [0.1764706 ]],\n",
       " \n",
       "         [[0.45490196],\n",
       "          [0.45490196],\n",
       "          [0.45490196],\n",
       "          ...,\n",
       "          [0.14901961],\n",
       "          [0.15686275],\n",
       "          [0.18431373]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.15294118],\n",
       "          [0.15294118],\n",
       "          [0.15294118],\n",
       "          ...,\n",
       "          [0.14901961],\n",
       "          [0.16078432],\n",
       "          [0.16470589]],\n",
       " \n",
       "         [[0.15294118],\n",
       "          [0.15294118],\n",
       "          [0.15294118],\n",
       "          ...,\n",
       "          [0.13725491],\n",
       "          [0.14901961],\n",
       "          [0.15294118]],\n",
       " \n",
       "         [[0.15294118],\n",
       "          [0.15294118],\n",
       "          [0.15294118],\n",
       "          ...,\n",
       "          [0.12941177],\n",
       "          [0.13725491],\n",
       "          [0.14509805]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.16078432],\n",
       "          [0.16078432],\n",
       "          [0.15686275],\n",
       "          ...,\n",
       "          [0.24313726],\n",
       "          [0.24705882],\n",
       "          [0.2509804 ]],\n",
       " \n",
       "         [[0.15686275],\n",
       "          [0.15686275],\n",
       "          [0.15294118],\n",
       "          ...,\n",
       "          [0.24705882],\n",
       "          [0.2509804 ],\n",
       "          [0.25490198]],\n",
       " \n",
       "         [[0.15294118],\n",
       "          [0.14901961],\n",
       "          [0.14509805],\n",
       "          ...,\n",
       "          [0.24313726],\n",
       "          [0.2509804 ],\n",
       "          [0.25882354]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.8980392 ],\n",
       "          [0.88235295],\n",
       "          [0.8666667 ],\n",
       "          ...,\n",
       "          [0.6784314 ],\n",
       "          [0.6627451 ],\n",
       "          [0.64705884]],\n",
       " \n",
       "         [[0.9098039 ],\n",
       "          [0.8980392 ],\n",
       "          [0.8862745 ],\n",
       "          ...,\n",
       "          [0.6431373 ],\n",
       "          [0.627451  ],\n",
       "          [0.6156863 ]],\n",
       " \n",
       "         [[0.91764706],\n",
       "          [0.9098039 ],\n",
       "          [0.8980392 ],\n",
       "          ...,\n",
       "          [0.6156863 ],\n",
       "          [0.6       ],\n",
       "          [0.5882353 ]]],\n",
       " \n",
       " \n",
       "        [[[0.46666667],\n",
       "          [0.53333336],\n",
       "          [0.54509807],\n",
       "          ...,\n",
       "          [0.43137255],\n",
       "          [0.42352942],\n",
       "          [0.4392157 ]],\n",
       " \n",
       "         [[0.49019608],\n",
       "          [0.5411765 ],\n",
       "          [0.5411765 ],\n",
       "          ...,\n",
       "          [0.4117647 ],\n",
       "          [0.39215687],\n",
       "          [0.41568628]],\n",
       " \n",
       "         [[0.5137255 ],\n",
       "          [0.5411765 ],\n",
       "          [0.5254902 ],\n",
       "          ...,\n",
       "          [0.41568628],\n",
       "          [0.36862746],\n",
       "          [0.39215687]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.1882353 ],\n",
       "          [0.1882353 ],\n",
       "          [0.18039216],\n",
       "          ...,\n",
       "          [0.21176471],\n",
       "          [0.23529412],\n",
       "          [0.2       ]],\n",
       " \n",
       "         [[0.14901961],\n",
       "          [0.15686275],\n",
       "          [0.16078432],\n",
       "          ...,\n",
       "          [0.1882353 ],\n",
       "          [0.22352941],\n",
       "          [0.17254902]],\n",
       " \n",
       "         [[0.13333334],\n",
       "          [0.14901961],\n",
       "          [0.16078432],\n",
       "          ...,\n",
       "          [0.1764706 ],\n",
       "          [0.20784314],\n",
       "          [0.14117648]]],\n",
       " \n",
       " \n",
       "        [[[0.32941177],\n",
       "          [0.32156864],\n",
       "          [0.4117647 ],\n",
       "          ...,\n",
       "          [0.3529412 ],\n",
       "          [0.33333334],\n",
       "          [0.3137255 ]],\n",
       " \n",
       "         [[0.34509805],\n",
       "          [0.34117648],\n",
       "          [0.41568628],\n",
       "          ...,\n",
       "          [0.35686275],\n",
       "          [0.34509805],\n",
       "          [0.33333334]],\n",
       " \n",
       "         [[0.35686275],\n",
       "          [0.35686275],\n",
       "          [0.41960785],\n",
       "          ...,\n",
       "          [0.36078432],\n",
       "          [0.35686275],\n",
       "          [0.36078432]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.5294118 ],\n",
       "          [0.5176471 ],\n",
       "          [0.5137255 ],\n",
       "          ...,\n",
       "          [0.627451  ],\n",
       "          [0.69803923],\n",
       "          [0.7490196 ]],\n",
       " \n",
       "         [[0.53333336],\n",
       "          [0.5137255 ],\n",
       "          [0.50980395],\n",
       "          ...,\n",
       "          [0.62352943],\n",
       "          [0.7019608 ],\n",
       "          [0.7529412 ]],\n",
       " \n",
       "         [[0.53333336],\n",
       "          [0.50980395],\n",
       "          [0.5058824 ],\n",
       "          ...,\n",
       "          [0.6431373 ],\n",
       "          [0.7294118 ],\n",
       "          [0.7647059 ]]]], dtype=float32),\n",
       " array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it generates real samples from the dataset\n",
    "generate_real_samples(dataset=load_real_samples(r\"C:\\Users\\Alberto Parenti\\Downloads\\STUDY\\NOVA IMS\\DEEP LEARNING\\PROJECT\\crop_part1 (extract.me)\\crop_part1\"), n_samples = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(seed_size, channels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(4*4*256,activation=\"relu\",input_dim=seed_size))\n",
    "    model.add(Reshape((4,4,256)))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "   \n",
    "    # Output resolution, additional upsampling\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    if GENERATE_RES>1:\n",
    "      model.add(UpSampling2D(size=(GENERATE_RES,GENERATE_RES)))\n",
    "      model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "      model.add(BatchNormalization(momentum=0.8))\n",
    "      model.add(Activation(\"relu\"))\n",
    "\n",
    "    # Final CNN layer\n",
    "    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 96, 96, 3), dtype=float32, numpy=\n",
       "array([[[[ 0.00520813, -0.00457027,  0.01439242],\n",
       "         [-0.00742599, -0.03526122,  0.01033687],\n",
       "         [ 0.00327804, -0.04023036,  0.01260732],\n",
       "         ...,\n",
       "         [ 0.00138838, -0.02279679, -0.00480669],\n",
       "         [ 0.00374344, -0.01639503, -0.00153476],\n",
       "         [-0.00331591, -0.00572373,  0.00067873]],\n",
       "\n",
       "        [[-0.00078958, -0.01641302,  0.01373376],\n",
       "         [-0.01319755, -0.05693582,  0.02874551],\n",
       "         [-0.00061102, -0.06726126,  0.02339455],\n",
       "         ...,\n",
       "         [-0.00648004, -0.02550304, -0.00385213],\n",
       "         [-0.00372244, -0.02179736,  0.00878283],\n",
       "         [-0.01093831, -0.00365467,  0.0054998 ]],\n",
       "\n",
       "        [[-0.00046098, -0.01538005,  0.00736164],\n",
       "         [-0.02332798, -0.07526054,  0.00696865],\n",
       "         [-0.00876229, -0.09197112,  0.01753742],\n",
       "         ...,\n",
       "         [-0.01567685, -0.02872184,  0.00521487],\n",
       "         [-0.0107264 , -0.01900603,  0.01602516],\n",
       "         [-0.02382853, -0.00592685,  0.00780756]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.00388971,  0.00113615,  0.0175933 ],\n",
       "         [-0.00796425, -0.02822934,  0.02374594],\n",
       "         [ 0.00226591, -0.02820029,  0.02874109],\n",
       "         ...,\n",
       "         [ 0.01191598, -0.04370471,  0.04081262],\n",
       "         [ 0.00057706, -0.02776768,  0.04224548],\n",
       "         [-0.00904081, -0.02350713,  0.02429401]],\n",
       "\n",
       "        [[-0.00119613,  0.0037127 ,  0.02382348],\n",
       "         [ 0.00377525, -0.01794031,  0.03373621],\n",
       "         [ 0.01686353, -0.02330624,  0.03913431],\n",
       "         ...,\n",
       "         [ 0.0183159 , -0.02927773,  0.03345695],\n",
       "         [ 0.00895989, -0.02319648,  0.03438538],\n",
       "         [-0.00115833, -0.02328302,  0.01376294]],\n",
       "\n",
       "        [[-0.00858966,  0.00997862,  0.0185267 ],\n",
       "         [-0.00343755,  0.00485048,  0.02649503],\n",
       "         [-0.00361311,  0.00312348,  0.02716266],\n",
       "         ...,\n",
       "         [ 0.01177277, -0.01021752,  0.03347561],\n",
       "         [ 0.00398305, -0.00950441,  0.03802507],\n",
       "         [ 0.00056142, -0.00734758,  0.0138904 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = build_generator(SEED_SIZE, IMAGE_CHANNELS)\n",
    "noise = tf.random.normal([1, SEED_SIZE])\n",
    "generated_image = generator(noise, training=False)\n",
    "generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.500049]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "image_shape = (GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS)\n",
    "\n",
    "discriminator = define_discriminator(image_shape)\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Both the generator and discriminator use Adam and the same learning rate and momentum. This does not need to be the case. If you use a GENERATE_RES greater than 3 you may need to tune\n",
    " these learning rates, as well as other training and hyperparameters.'''\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function #  the use of `tf.function` causes the function to be \"compiled\"\n",
    "def train_step(images):\n",
    "  seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    generated_images = generator(seed, training=True)\n",
    "\n",
    "    real_output = discriminator(images, training=True)\n",
    "    fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(\\\n",
    "        gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(\\\n",
    "        disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(\n",
    "        gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(\n",
    "        gradients_of_discriminator, \n",
    "        discriminator.trainable_variables))\n",
    "  return gen_loss,disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(cnt,noise):\n",
    "  image_array = np.full(( \n",
    "      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
    "      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), IMAGE_CHANNELS), \n",
    "      255, dtype=np.uint8)\n",
    "  \n",
    "  generated_images = generator.predict(noise)\n",
    "\n",
    "  generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "  image_count = 0\n",
    "  for row in range(PREVIEW_ROWS):\n",
    "      for col in range(PREVIEW_COLS):\n",
    "        r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "        c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "        image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] \\\n",
    "            = generated_images[image_count] * 255\n",
    "        image_count += 1\n",
    "\n",
    "          \n",
    "  output_path = os.path.join(DATA_FOLDER,'output')\n",
    "  if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "  \n",
    "  filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
    "  im = Image.fromarray(image_array)\n",
    "  im.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, \n",
    "                                       SEED_SIZE))\n",
    "  start = time.time()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    gen_loss_list = []\n",
    "    disc_loss_list = []\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      t = train_step(image_batch)\n",
    "      gen_loss_list.append(t[0])\n",
    "      disc_loss_list.append(t[1])\n",
    "\n",
    "    g_loss = sum(gen_loss_list) / len(gen_loss_list)\n",
    "    d_loss = sum(disc_loss_list) / len(disc_loss_list)\n",
    "\n",
    "    epoch_elapsed = time.time()-epoch_start\n",
    "    print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss},'\\\n",
    "           f' {hms_string(epoch_elapsed)}')\n",
    "    save_images(epoch,fixed_seed)\n",
    "\n",
    "  elapsed = time.time()-start\n",
    "  print (f'Training time: {hms_string(elapsed)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(training_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\ALBERT~1\\AppData\\Local\\Temp/ipykernel_7628/624590007.py\", line 8, in train_step  *\n        real_output = discriminator(images, training=True)\n    File \"C:\\Users\\Alberto Parenti\\anaconda3\\envs\\datamining_practical\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Alberto Parenti\\anaconda3\\envs\\datamining_practical\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 96, 96, 3), found shape=(32, 200, 200, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALBERT~1\\AppData\\Local\\Temp/ipykernel_7628/2228458018.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ALBERT~1\\AppData\\Local\\Temp/ipykernel_7628/2845291803.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m       \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m       \u001b[0mgen_loss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m       \u001b[0mdisc_loss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\datamining_practical\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\datamining_practical\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\ALBERT~1\\AppData\\Local\\Temp/ipykernel_7628/624590007.py\", line 8, in train_step  *\n        real_output = discriminator(images, training=True)\n    File \"C:\\Users\\Alberto Parenti\\anaconda3\\envs\\datamining_practical\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Alberto Parenti\\anaconda3\\envs\\datamining_practical\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 96, 96, 3), found shape=(32, 200, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "# generate n fake samples with class labels as for the time being we don't have a generator model\n",
    "def generate_fake_samples_test(n_samples):\n",
    "\tfrom keras.preprocessing.image import array_to_img\n",
    "\n",
    "\t# generate uniform random numbers in [0,1]\n",
    "\tX = rand(200 * 200 * n_samples)\n",
    "\t# reshape into a batch of grayscale images\n",
    "\tX = X.reshape((n_samples, 200, 200, 1))\n",
    "\n",
    "\tfor array in X:\n",
    "\t\timg = array_to_img(array)\n",
    "\t\timg.show()\n",
    "\t\tbreak\n",
    "\n",
    "generate_fake_samples_test(400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALBERT~1\\AppData\\Local\\Temp/ipykernel_7628/980164992.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"face_generator.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'DATA_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "generator.save(os.path.join(DATA_FOLDER,\"face_generator.h5\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "489273d9e700296fcf9e47b32fa24414c858b77e187d8a326e595227c9517409"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
